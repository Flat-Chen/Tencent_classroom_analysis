{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    '''\n",
    "        CREATE TABLE IF NOT EXISTS txkt.dws_organ\n",
    "        (\n",
    "          `organ_name`                   STRING COMMENT '视频ID',\n",
    "          `charge_video_num`             BIGINT COMMENT '机构收费视频数',\n",
    "          `free_video_num`               BIGINT COMMENT '机构免费视频数', \n",
    "          `expensive_video_price`        BIGINT COMMENT '机构最贵视频价格',\n",
    "          `cheap_video_price`            BIGINT COMMENT '机构最便宜视频价格',    \n",
    "          `organ_all_person_num`         BIGINT COMMENT '机构累计学习人数',\n",
    "          `organ_all_charge_person_num`  BIGINT COMMENT '机构视频购买总人数',\n",
    "          `max_study_video`              STRING COMMENT '机构学习人数最多视频',       \n",
    "          `avg_page`                     BIGINT COMMENT '机构课程平均所在页数',\n",
    "          `add_study_num_1d`             BIGINT COMMENT '机构近一天增加学习人数',\n",
    "          `add_study_num_3d`             BIGINT COMMENT '机构近三天增加学习人数',\n",
    "          `add_study_num_10d`            BIGINT COMMENT '机构近十天增加学习人数',\n",
    "          `add_study_num_1d_max_video`   STRING COMMENT '机构近一天增加学习人数最多的视频ID',\n",
    "          `add_study_num_3d_max_video`   STRING COMMENT '机构近三天增加学习人数最多的视频ID',\n",
    "          `add_study_num_10d_max_video`  STRING COMMENT '机构近十天增加学习人数最多的视频ID',\n",
    "          `add_person_num_1d`            BIGINT COMMENT '机构近一天增加购买/报名人数',\n",
    "          `add_person_num_3d`            BIGINT COMMENT '机构近三天增加购买/报名人数',\n",
    "          `add_person_num_10d`           BIGINT COMMENT '机构近十天增加购买/报名人数', \n",
    "          `add_person_num_1d_max_video`  STRING COMMENT '机构近一天增加购买/报名人数最多的的视频ID',\n",
    "          `add_person_num_3d_max_video`  STRING COMMENT '机构近三天增加购买/报名人数最多的的视频ID',\n",
    "          `add_person_num_10d_max_video` STRING COMMENT '机构近十天增加购买/报名人数最多的的视频ID', \n",
    "          `profit_num_td`                BIGINT COMMENT '机构累计收益（分）',\n",
    "          `profit_num_1d`                BIGINT COMMENT '机构近一天收益（分）',\n",
    "          `profit_num_3d`                BIGINT COMMENT '机构近三天收益（分）',\n",
    "          `profit_num_10d`               BIGINT COMMENT '机构近十天收益（分）', \n",
    "          `etl_time`                     STRING COMMENT '数据加工时间'      \n",
    "        ) \n",
    "        PARTITIONED BY (`dt` STRING) \n",
    "        STORED AS PARQUET\n",
    "    '''\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    '''\n",
    "      INSERT OVERWRITE TABLE txkt.dws_organ PARTITION (dt = '{dt}')\n",
    "      SELECT dim_organ.organ_name,\n",
    "             charge_video_num,\n",
    "             free_video_num,\n",
    "             expensive_video_price,\n",
    "             cheap_video_price,\n",
    "             organ_all_person_num,\n",
    "             organ_all_charge_person_num,\n",
    "             max_study_video,\n",
    "             avg_page,\n",
    "             add_study_num_1d,\n",
    "             add_study_num_3d,\n",
    "             add_study_num_10d,\n",
    "             add_study_num_1d_max_video,\n",
    "             add_study_num_3d_max_video,\n",
    "             add_study_num_10d_max_video,\n",
    "             add_person_num_1d,\n",
    "             add_person_num_3d,\n",
    "             add_person_num_10d,\n",
    "             add_person_num_1d_max_video,\n",
    "             add_person_num_3d_max_video,\n",
    "             add_person_num_10d_max_video,\n",
    "             profit_num_td,\n",
    "             profit_num_1d,\n",
    "             profit_num_3d,\n",
    "             profit_num_10d,\n",
    "             FROM_UNIXTIME(CAST(NOW() AS BIGINT), 'yyyy-MM-dd HH:mm:ss')  AS elt_time\n",
    "        FROM (\n",
    "               SELECT organ_name,\n",
    "                      CAST(organ_all_person_num AS BIGINT) AS organ_all_person_num\n",
    "                 FROM txkt.dim_organ_df\n",
    "                WHERE dt = '{dt}'\n",
    "             ) AS dim_organ\n",
    "   LEFT JOIN ( \n",
    "               SELECT organ_name,\n",
    "                      SUM(CASE WHEN price > 0 THEN 1 ELSE 0 END)                               AS charge_video_num,\n",
    "                      SUM(CASE WHEN price = 0 THEN 1 ELSE 0 END)                               AS free_video_num,\n",
    "                      MAX(price)                                                               AS expensive_video_price,\n",
    "                      MAX(CASE WHEN price > 0 THEN price ELSE NULL END)                        AS cheap_video_price,\n",
    "                      SUM(CASE WHEN price > 0 THEN today.person_num ELSE 0 END)                AS organ_all_charge_person_num,\n",
    "                      MAX(CASE WHEN study_video_rank = 1 THEN today.video_id ELSE NULL END)          AS max_study_video,\n",
    "                      AVG(video_index_page)                                                    AS avg_page,\n",
    "                      SUM((NVL(today.recently_study_num, 0) -  NVL(d1.recently_study_num, 0))) AS add_study_num_1d,\n",
    "                      SUM((NVL(today.recently_study_num, 0) -  NVL(d3.recently_study_num, 0))) AS add_study_num_3d,\n",
    "                      SUM((NVL(today.recently_study_num, 0) - NVL(d10.recently_study_num, 0))) AS add_study_num_10d,\n",
    "                      SUM((NVL(today.person_num, 0) -  NVL(d1.person_num, 0)))                 AS add_person_num_1d,\n",
    "                      SUM((NVL(today.person_num, 0) -  NVL(d3.person_num, 0)))                 AS add_person_num_3d,\n",
    "                      SUM((NVL(today.person_num, 0) - NVL(d10.person_num, 0)))                 AS add_person_num_10d,\n",
    "                      SUM(today.person_num                                    * price)         AS profit_num_td,\n",
    "                      SUM((NVL(today.person_num, 0) -  NVL(d1.person_num, 0)) * price)         AS profit_num_1d,\n",
    "                      SUM((NVL(today.person_num, 0) -  NVL(d3.person_num, 0)) * price)         AS profit_num_3d,\n",
    "                      SUM((NVL(today.person_num, 0) - NVL(d10.person_num, 0)) * price)         AS profit_num_10d\n",
    "                 FROM (\n",
    "                         SELECT video_id,\n",
    "                                recently_study_num, \n",
    "                                person_num,\n",
    "                                price,\n",
    "                                organ_name,\n",
    "                                video_index_page,\n",
    "                                ROW_NUMBER() OVER(PARTITION BY organ_name ORDER BY person_num DESC) AS study_video_rank\n",
    "                           FROM txkt.dim_video_df\n",
    "                          WHERE dt = '{dt}'\n",
    "                      ) AS today\n",
    "            LEFT JOIN (\n",
    "                        SELECT video_id,\n",
    "                               recently_study_num, \n",
    "                               person_num\n",
    "                          FROM txkt.dim_video_df\n",
    "                         WHERE dt = DATE_SUB('{dt}',1)\n",
    "                      ) AS d1\n",
    "                   ON today.video_id = d1.video_id\n",
    "            LEFT JOIN (\n",
    "                        SELECT video_id,\n",
    "                               recently_study_num, \n",
    "                               person_num\n",
    "                          FROM txkt.dim_video_df\n",
    "                         WHERE dt = DATE_SUB('{dt}', 3)\n",
    "                      ) AS d3\n",
    "                   ON today.video_id = d3.video_id\n",
    "            LEFT JOIN (\n",
    "                        SELECT video_id,\n",
    "                               recently_study_num, \n",
    "                               person_num\n",
    "                          FROM txkt.dim_video_df\n",
    "                         WHERE dt = DATE_SUB('{dt}', 10)\n",
    "                      ) AS d10\n",
    "                   ON today.video_id = d10.video_id\n",
    "             GROUP BY organ_name\n",
    "             ) AS organ_info\n",
    "          ON dim_organ.organ_name = organ_info.organ_name\n",
    "   LEFT JOIN (\n",
    "               SELECT organ_name,\n",
    "                      MAX(CASE WHEN add_study_num_1d_rk  = 1 THEN dws_video.video_id ELSE NULL END ) AS add_study_num_1d_max_video,\n",
    "                      MAX(CASE WHEN add_study_num_3d_rk  = 1 THEN dws_video.video_id ELSE NULL END ) AS add_study_num_3d_max_video,\n",
    "                      MAX(CASE WHEN add_study_num_10d_rk = 1 THEN dws_video.video_id ELSE NULL END ) AS add_study_num_10d_max_video,\n",
    "                      MAX(CASE WHEN add_person_num_1d_rk = 1 THEN dws_video.video_id ELSE NULL END ) AS add_person_num_1d_max_video,\n",
    "                      MAX(CASE WHEN add_person_num_3d_rk = 1 THEN dws_video.video_id ELSE NULL END ) AS add_person_num_3d_max_video,\n",
    "                      MAX(CASE WHEN add_person_num_10_rk = 1 THEN dws_video.video_id ELSE NULL END ) AS add_person_num_10d_max_video\n",
    "                 FROM (\n",
    "                        SELECT video_id,\n",
    "                               ROW_NUMBER() OVER(PARTITION BY video_id ORDER BY add_study_num_1d   DESC )AS add_study_num_1d_rk,\n",
    "                               ROW_NUMBER() OVER(PARTITION BY video_id ORDER BY add_study_num_3d   DESC )AS add_study_num_3d_rk,\n",
    "                               ROW_NUMBER() OVER(PARTITION BY video_id ORDER BY add_study_num_10d  DESC )AS add_study_num_10d_rk,\n",
    "                               ROW_NUMBER() OVER(PARTITION BY video_id ORDER BY add_person_num_1d  DESC )AS add_person_num_1d_rk,\n",
    "                               ROW_NUMBER() OVER(PARTITION BY video_id ORDER BY add_person_num_3d  DESC )AS add_person_num_3d_rk,\n",
    "                               ROW_NUMBER() OVER(PARTITION BY video_id ORDER BY add_person_num_10d DESC )AS add_person_num_10_rk\n",
    "                          FROM txkt.dws_video \n",
    "                         WHERE dt = '{dt}'\n",
    "                      ) AS dws_video\n",
    "           INNER JOIN (\n",
    "                        SELECT video_id,\n",
    "                               organ_name\n",
    "                          FROM txkt.dim_video_df\n",
    "                         WHERE dt = '{dt}'\n",
    "                      ) AS dim_video\n",
    "                   ON dws_video.video_id = dim_video.video_id\n",
    "             GROUP BY organ_name\n",
    "             ) AS video_info \n",
    "          ON dim_organ.organ_name = video_info.organ_name\n",
    "    '''.format(dt='2022-03-27')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33773)\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/pyspark/lib/python3.6/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/pyspark/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:33773)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.6/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;34m<\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \"\"\".format(\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mcatalogImplementation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.sql.catalogImplementation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0msc_HTML\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_html_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.6/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mconf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \"\"\"\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_conf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRuntimeConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1029\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \"\"\"\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    983\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    984\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1125\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:33773)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f421b73f470>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
